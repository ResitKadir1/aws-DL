{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks Exercises Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "You've been hired by a shipping company to overhaul the way they route mail, parcels and packages. They want to build an image recognition system  capable of recognizing the digits in the zipcode on a package, so that it can be automatically routed to the correct location.\n",
    "You are tasked to build the digit recognition system. Luckily, you can rely on the MNIST dataset for the intial training of your model!\n",
    "\n",
    "Build a deep convolutional neural network with at least two convolutional and two pooling layers before the fully connected layer.\n",
    "\n",
    "- Start from the network we have just built\n",
    "- Insert a `Conv2D` layer after the first `MaxPool2D`, give it 64 filters.\n",
    "- Insert a `MaxPool2D` after that one\n",
    "- Insert an `Activation` layer\n",
    "- retrain the model\n",
    "- does performance improve?\n",
    "- how many parameters does this new model have? More or less than the previous model? Why?\n",
    "- how long did this second model take to train? Longer or shorter than the previous model? Why?\n",
    "- did it perform better or worse than the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data(('/tmp/mnist.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 05:46:07.149595: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 225,034\n",
      "Trainable params: 225,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-03 05:46:07.446382: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "329/329 [==============================] - 37s 108ms/step - loss: 0.2555 - accuracy: 0.9200 - val_loss: 0.0990 - val_accuracy: 0.9689\n",
      "Epoch 2/2\n",
      "329/329 [==============================] - 32s 97ms/step - loss: 0.0673 - accuracy: 0.9789 - val_loss: 0.0544 - val_accuracy: 0.9836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffce91a35d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat, batch_size=128,\n",
    "          epochs=2, verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0444 - accuracy: 0.9868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04442313313484192, 0.9868000149726868]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Pleased with your performance with the digits recognition task, your boss decides to challenge you with a harder task. Their online branch allows people to upload images to a website that generates and prints a postcard that is shipped to destination. Your boss would like to know what images people are loading on the site in order to provide targeted advertising on the same page, so he asks you to build an image recognition system capable of recognizing a few objects. Luckily for you, there's a dataset ready made with a collection of labeled images. This is the [Cifar 10 Dataset](http://www.cs.toronto.edu/~kriz/cifar.html), a very famous dataset that contains images for 10 different categories:\n",
    "\n",
    "- airplane \t\t\t\t\t\t\t\t\t\t\n",
    "- automobile \t\t\t\t\t\t\t\t\t\t\n",
    "- bird \t\t\t\t\t\t\t\t\t\t\n",
    "- cat \t\t\t\t\t\t\t\t\t\t\n",
    "- deer \t\t\t\t\t\t\t\t\t\t\n",
    "- dog \t\t\t\t\t\t\t\t\t\t\n",
    "- frog \t\t\t\t\t\t\t\t\t\t\n",
    "- horse \t\t\t\t\t\t\t\t\t\t\n",
    "- ship \t\t\t\t\t\t\t\t\t\t\n",
    "- truck\n",
    "\n",
    "In this exercise we will reach the limit of what you can achieve on your laptop and get ready for the next session on cloud GPUs.\n",
    "\n",
    "Here's what you have to do:\n",
    "- load the cifar10 dataset using `keras.datasets.cifar10.load_data()`\n",
    "- display a few images, see how hard/easy it is for you to recognize an object with such low resolution\n",
    "- check the shape of X_train, does it need reshape?\n",
    "- check the scale of X_train, does it need rescaling?\n",
    "- check the shape of y_train, does it need reshape?\n",
    "- build a model with the following architecture, and choose the parameters and activation functions for each of the layers:\n",
    "    - conv2d\n",
    "    - conv2d\n",
    "    - maxpool\n",
    "    - conv2d\n",
    "    - conv2d\n",
    "    - maxpool\n",
    "    - flatten\n",
    "    - dense\n",
    "    - output\n",
    "- compile the model and check the number of parameters\n",
    "- attempt to train the model with the optimizer of your choice. How fast does training proceed?\n",
    "- If training is too slow (as expected) stop the execution and move to the next session!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 16s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ffcfcf7e450>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train, 10)\n",
    "y_test_cat = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3),\n",
    "                 padding='same',\n",
    "                 input_shape=(32, 32, 3),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 218s 139ms/step - loss: 1.3986 - accuracy: 0.5013 - val_loss: 1.3628 - val_accuracy: 0.5346\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 218s 140ms/step - loss: 0.9052 - accuracy: 0.6856 - val_loss: 0.8020 - val_accuracy: 0.7213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ffcd239aad0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_cat,\n",
    "          batch_size=32,\n",
    "          epochs=2,\n",
    "          validation_data=(X_test, y_test_cat),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
